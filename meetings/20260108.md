# TODO

## 1. LLMs Alpha Discovery Works
要对现有 LLM 在 Alpha Discovery 方向的工作进行非常全面的调研，覆盖不同方法、不同范式和不同结论，重点不是列举，而是理解每一类方法真正解决了什么问题，以及它们的假设前提。  
时间节点是 next week，需要形成一个比较系统的认知框架，而不是零散的 paper list。

---

## 2. 复现经典以及最新的 Alpha 挖掘因子
需要选择一些具有代表性的、被频繁引用的、以及最近较新的 alpha 挖掘工作进行复现。  
复现的目的不是跑通结果，而是系统性地拆解问题，比如：

- 是否存在 1、2、3 类常见 failure mode  
- 比如 sen 提到的 prompt 的结果不太 robust  
- 这种不 robust 的根源是什么  
- 是否来自 prompt 本身、数据切分、评价方式、或者搜索空间  

以及进一步思考可以如何去解决这些问题，而不是只停留在现象层面。

---

## 3. 只用 prompt 的方法本身的问题
当前只用 prompt 的方式，虽然在 narrative 和 story 上可以讲得很好，但最终一定会在某些关键环节暴露问题。  
需要刻意去寻找它没有找到的问题，而不是验证它已经能做什么。  
同时需要对传统方法保持足够了解，用传统方法作为对照，去看 prompt-only 方法在什么地方天然存在缺陷，哪些问题是它结构性无法解决的。

---

# IDEAS

## 1. 不只考虑 API 级别的使用，也要考虑 fine-tune
研究方向不应只停留在调用现成 API，而是要系统性考虑 fine-tune 的可能性，包括：

- 在什么任务上 fine-tune 是有意义的  
- fine-tune 是否能缓解 prompt 不稳定的问题  
- fine-tune 带来的 inductive bias 是否更符合金融或其他领域的需求  

---

## 2. LLM 不需要覆盖整个流程，而是参与局部模块
不是用 LLM 替代整个算法或 pipeline，而是让 LLM 替代或增强其中的某一个模块。  
比如在遗传算法中：

- LLM 只负责某些模块的 insight  
- 例如剪枝规则、参数设置、搜索空间约束  
- 或者为遗传算法提供某些启发式先验  

这种方式可能比 end-to-end 的 LLM 更稳健，也更容易形成 algorithmic contribution。

---

## 3. 不只做 Alpha Discovery，也要考虑 Strategy Discovery
Quant 中除了 alpha discovery，还有很多其他模块和流程。  
需要系统性思考：

- 是否存在其他更适合 LLM 介入的 process  
- Strategy discovery 是否比单一 alpha 更有结构优势  
- LLM 是否更擅长高层结构设计，而非低层数值优化  

---

## 4. 用大模型简化其他 deep learning 或 learning 方法
不一定要用 LLM 直接做预测，也可以让大模型作为工具来：

- 加速已有 learning 方法  
- 简化模型结构  
- 减少搜索空间  
- 或在表现上取得更稳定的结果  

目标是让整个 learning pipeline 更高效、更可控，而不是更复杂。

---

## 5. 如果真的有 16 个 H200 的资源
在算力资源充足的情况下，需要认真思考如何最大化其研究价值，包括：

- 是否训练一个大模型  
- 是否针对特定任务进行大规模 fine-tune  
- 是否可以探索一些 API 调用无法完成的实验设置  

而不是简单地重复已有的小规模实验。

---

## 6. 不只局限于 Quant，也考虑 Social Science 问题
不只是在 quant 场景下找 alpha，在很多行业和社会科学问题中也存在 good 因子，而且这些因子往往更强调可解释性。  
可以考虑：

- 找几个经典的 setting  
- 设计一个 agent，能够按照这些 setting 的标准格式输入  
- 比如在 finance 中验证因子好不好，不只看 IC，还看其他 variant 的统计 test  

在此基础上：

- 自动生成一些因子  
- 或对已有模型进行改进  
- 强调 financial 或 domain-specific 的约束  

同时可以针对金融数据中非常容易发生的问题，比如数据泄露或其他常见陷阱，提出系统性的解决方式。  
这些问题在计算机领域的人看来可能是新颖的。

---

## 7. 反直觉但重要的相关关系
Finance 中有很多反直觉、但逻辑上成立的关系，是人类容易理解、但模型很难学出来的。  
比如机票价格高本身可能是好事，代表需求高，从而上座率会更高。  
需要思考：

- 为什么传统模型或 AI 模型学不出来  
- LLM 是否在解释层面具备优势  
- 是否可以将这种解释能力转化为结构性约束或因子设计  

---

## 8. 多智能体不应只是讲故事
多智能体系统如果只是 narrative-driven，是不够的。  
更理想的方向是：

- 是否能在算法层面形成真正的 contribution  
- 多智能体是否能对应不同的功能模块  
- 它们之间的交互是否能被形式化，而不是仅靠 prompt 描述  

---

## 9. 对现有 finance 研究范式的反思
当前做 finance 的人中：

- 有些 theory 看起来很好，但实际效果并不理想  
- 有些 technique 又不够 sound  
- 数据一多，总能找到一个看起来还行的 model  
- 最后往往又回到讲故事  

尽管如此，仍然可以多找这些人聊，理解他们的真实痛点和隐含假设。

---

## 10. 区块链相关的数据与 protocol
区块链上的数据在 finance 或 quant 中用得不多，但往往具有独特的结构和 protocol 特性。  
可以探索：

- 是否存在 quant 领域未充分利用的数据  
- 是否可以利用 protocol-level 的约束或机制  
- 是否能形成与传统金融数据完全不同的研究视角  
